{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logging.disable(logging.CRITICAL)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from darts.metrics import mae\n",
    "from darts.models import TiDEModel, TSMixerModel, DLinearModel\n",
    "from darts.utils.likelihood_models import QuantileRegression\n",
    "from darts.utils.callbacks import TFMProgressBar\n",
    "from darts import TimeSeries\n",
    "from src.CausalVAR.fitting import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../../data/census_shifted.csv')"
   ],
   "id": "c08efe6e7147db2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast_horizon = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d9954d666f3bd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert 'Year' to datetime\n",
    "df['Year'] = pd.to_datetime(df['Year'])\n",
    "\n",
    "# Calculate the total population for each 'Name' in 1991\n",
    "df_1991 = df[df['Year'].dt.year == 1991].copy()\n",
    "df_1991['Total Population 1991'] = df_1991['Population 0-14'] + df_1991['Population 15-64'] + df_1991['Population 65+']\n",
    "\n",
    "# Create a dictionary to map 'Name' to 'Total Population 1991'\n",
    "population_1991_dict = df_1991.set_index('Name')['Total Population 1991'].to_dict()\n",
    "\n",
    "# Scale the specified columns for all years for each 'Name'\n",
    "columns_to_scale = ['Population 0-14', 'Population 15-64', 'Population 65+', 'Births', 'Deaths', 'Migrations']\n",
    "for col in columns_to_scale:\n",
    "    df[col] = df.apply(lambda row: row[col] / population_1991_dict[row['Name']], axis=1)\n",
    "\n",
    "# Display the first few rows of the modified dataframe\n",
    "df.head()"
   ],
   "id": "3b9a7c88f850abe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "column_names = list(df.iloc[:,2:].columns)\n",
    "df[column_names]=df[column_names].astype('float32')\n",
    "'''series_names = {}\n",
    "for name in list(df['Name'].unique()):\n",
    "    series_names[name] = TimeSeries.from_dataframe(df[df['Name']==name],time_col='Year',value_cols=column_names).astype('float32')'''\n",
    "series = TimeSeries.from_group_dataframe(df,group_cols='Name',time_col='Year',value_cols=column_names)\n"
   ],
   "id": "47ed52ac88e7194",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = []\n",
    "val = []\n",
    "test = [] \n",
    "for state in series:\n",
    "    train_t, temp = state.split_after(0.5)\n",
    "    val_t, test_t = temp.split_after(0.5)\n",
    "    train.append(train_t)\n",
    "    val.append(val_t)\n",
    "    test.append(test_t)"
   ],
   "id": "922593c289115340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_params(\n",
    "    input_chunk_length: int,\n",
    "    output_chunk_length: int,\n",
    "    full_training=True,\n",
    "):\n",
    "    # early stopping: this setting stops training once the the validation\n",
    "    # loss has not decreased by more than 1e-5 for 10 epochs\n",
    "    early_stopper = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        min_delta=1e-5,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    # PyTorch Lightning Trainer arguments (you can add any custom callback)\n",
    "    if full_training:\n",
    "        limit_train_batches = None\n",
    "        limit_val_batches = None\n",
    "        max_epochs = 200\n",
    "        batch_size = 256\n",
    "    else:\n",
    "        limit_train_batches = 20\n",
    "        limit_val_batches = 10\n",
    "        max_epochs = 40\n",
    "        batch_size = 64\n",
    "\n",
    "    # only show the training and prediction progress bars\n",
    "    progress_bar = TFMProgressBar(\n",
    "        enable_sanity_check_bar=False, enable_train_bar=False, enable_validation_bar=False\n",
    "    )\n",
    "    pl_trainer_kwargs = {\n",
    "        \"gradient_clip_val\": 1,\n",
    "        \"max_epochs\": max_epochs,\n",
    "        \"limit_train_batches\": limit_train_batches,\n",
    "        \"limit_val_batches\": limit_val_batches,\n",
    "        \"accelerator\": \"auto\",\n",
    "        \"callbacks\": [early_stopper, progress_bar],\n",
    "    }\n",
    "\n",
    "    # optimizer setup, uses Adam by default\n",
    "    optimizer_cls = torch.optim.Adam\n",
    "    optimizer_kwargs = {\n",
    "        \"lr\": 1e-4,\n",
    "    }\n",
    "\n",
    "    # learning rate scheduler\n",
    "    lr_scheduler_cls = torch.optim.lr_scheduler.ExponentialLR\n",
    "    lr_scheduler_kwargs = {\"gamma\": 0.999}\n",
    "\n",
    "    # for probabilistic models, we use quantile regression, and set `loss_fn` to `None`\n",
    "    likelihood = QuantileRegression()\n",
    "    loss_fn = None\n",
    "\n",
    "    return {\n",
    "        \"input_chunk_length\": input_chunk_length,  # lookback window\n",
    "        \"output_chunk_length\": output_chunk_length,  # forecast/lookahead window\n",
    "        \"use_reversible_instance_norm\": True,\n",
    "        \"optimizer_kwargs\": optimizer_kwargs,\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": lr_scheduler_cls,\n",
    "        \"lr_scheduler_kwargs\": lr_scheduler_kwargs,\n",
    "        \"likelihood\": likelihood,  # use a `likelihood` for probabilistic forecasts\n",
    "        \"loss_fn\": loss_fn,  # use a `loss_fn` for determinsitic model\n",
    "        \"save_checkpoints\": True,  # checkpoint to retrieve the best performing model state,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "        \"add_encoders\": {\n",
    "            \"cyclic\": {\n",
    "                \"future\": [\"hour\", \"dayofweek\", \"month\"]\n",
    "            }  # add cyclic time axis encodings as future covariates\n",
    "        },\n",
    "    }"
   ],
   "id": "a779929726911b55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_chunk_length = 4\n",
    "output_chunk_length = 1\n",
    "use_static_covariates = False\n",
    "full_training = True"
   ],
   "id": "dab26e6436b0eb27",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn import MSELoss\n",
    "def create_params2(input_chunk_length, output_chunk_length, full_training=True):\n",
    "    early_stopper = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        min_delta=1e-5,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "\n",
    "    if full_training:\n",
    "        limit_train_batches = None\n",
    "        limit_val_batches = None\n",
    "        max_epochs = 200\n",
    "        batch_size = 256\n",
    "    else:\n",
    "        limit_train_batches = 20\n",
    "        limit_val_batches = 10\n",
    "        max_epochs = 40\n",
    "        batch_size = 64\n",
    "\n",
    "    progress_bar = TFMProgressBar(\n",
    "        enable_sanity_check_bar=False, enable_validation_bar=False\n",
    "    )\n",
    "    pl_trainer_kwargs = {\n",
    "        \"gradient_clip_val\": 1,\n",
    "        \"max_epochs\": max_epochs,\n",
    "        \"limit_train_batches\": limit_train_batches,\n",
    "        \"limit_val_batches\": limit_val_batches,\n",
    "        \"accelerator\": \"auto\",\n",
    "        \"callbacks\": [early_stopper, progress_bar],\n",
    "    }\n",
    "\n",
    "    optimizer_cls = torch.optim.Adam\n",
    "    optimizer_kwargs = {\n",
    "        \"lr\": 1e-4,\n",
    "    }\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"input_chunk_length\": input_chunk_length,\n",
    "        \"output_chunk_length\": output_chunk_length,\n",
    "        \"use_reversible_instance_norm\": True,\n",
    "        \"optimizer_kwargs\": optimizer_kwargs,\n",
    "        \"pl_trainer_kwargs\": pl_trainer_kwargs,\n",
    "        \"lr_scheduler_cls\": torch.optim.lr_scheduler.ExponentialLR,\n",
    "        \"lr_scheduler_kwargs\": {\"gamma\": 0.999},\n",
    "        \"loss_fn\": MSELoss(),\n",
    "        \"save_checkpoints\": True,\n",
    "        \"force_reset\": True,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"random_state\": 42,\n",
    "        \"add_encoders\": {\n",
    "            \"cyclic\": {\n",
    "                \"future\": [\"hour\", \"dayofweek\", \"month\"]\n",
    "            }\n",
    "        },\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be9612e4d75f1f9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create the models\n",
    "model_tsm = TSMixerModel(\n",
    "    **create_params(\n",
    "        input_chunk_length,\n",
    "        output_chunk_length,\n",
    "        full_training=full_training,\n",
    "    ),\n",
    "    use_static_covariates=use_static_covariates,\n",
    "    model_name=\"tsm\",\n",
    ")\n",
    "model_tide = TiDEModel(\n",
    "    **create_params(\n",
    "        input_chunk_length,\n",
    "        output_chunk_length,\n",
    "        full_training=full_training,\n",
    "    ),\n",
    "    use_static_covariates=use_static_covariates,\n",
    "    model_name=\"tide\",\n",
    ")\n",
    "model_dlinear = DLinearModel(\n",
    "    **create_params2(\n",
    "        input_chunk_length,\n",
    "        output_chunk_length=1,\n",
    "        full_training=full_training,\n",
    "    ),\n",
    "    use_static_covariates=use_static_covariates,\n",
    "    model_name=\"dlinear\",\n",
    ")\n",
    "models = {\n",
    "    \"TSM\": model_tsm,\n",
    "    \"TiDE\": model_tide, \n",
    "    \"Dlinear\": model_dlinear\n",
    "}"
   ],
   "id": "ab34e756b74536aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for model_name, model in models.items():\n",
    "    model.fit(\n",
    "        series=train,\n",
    "        val_series=val,\n",
    "    )\n",
    "    # load from checkpoint returns a new model object, we store it in the models dict\n",
    "    models[model_name] = model.load_from_checkpoint(\n",
    "        model_name=model.model_name, best=True\n",
    "    )"
   ],
   "id": "49f1502fbbe2e2a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "forecast_horizon = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16dde8b2b17d8537"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Perform backtesting with a rolling window\n",
    "predictions_tide = models['TiDE'].historical_forecasts(\n",
    "    series,\n",
    "    start=0,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    stride=1,\n",
    "    retrain=False,\n",
    "    last_points_only=True,\n",
    "    num_samples=1\n",
    ")\n",
    "for i in range(len(predictions_tide)):\n",
    "    predictions_tide[i] = predictions_tide[i].slice_intersect(test[0])\n",
    "\n",
    "predictions_tsm = models['TSM'].historical_forecasts(\n",
    "    series,\n",
    "    start=0,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    stride=1,\n",
    "    retrain=False,\n",
    "    last_points_only=True,\n",
    "    num_samples=1\n",
    ")\n",
    "for i in range(len(predictions_tsm)):\n",
    "    predictions_tsm[i] = predictions_tsm[i].slice_intersect(test[0])\n",
    "    \n",
    "predictions_dlinear = models['Dlinear'].historical_forecasts(\n",
    "    series,\n",
    "    start=0,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    stride=1,\n",
    "    retrain=False,\n",
    "    last_points_only=True,\n",
    "    num_samples=1\n",
    ")\n",
    "time_index_series = predictions_dlinear[0].time_index\n",
    "for i in range(len(predictions_dlinear)):\n",
    "    predictions_dlinear[i] = predictions_dlinear[i].slice_intersect(test[0])"
   ],
   "id": "cc390762cdfaf3af",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from SVAR.fitting_var_bounded import estimate_bounded\n",
    "df1 = pd.read_csv('census_shifted.csv')\n",
    "df_year = df1[\"Year\"]\n",
    "census = df1.drop([\"Year\"], axis=1)\n",
    "\n",
    "n_states = census['Name'].nunique()\n",
    "states = census['Name'].unique()\n",
    "\n",
    "rows = census['Name'].value_counts().sort_index()\n",
    "census.drop(['Name'], axis=1, inplace=True)\n",
    "cols = ['Births', 'Deaths', 'Migrations', 'Population 0-14', 'Population 15-64', 'Population 65+']\n",
    "census = census[cols]\n",
    "\n",
    "# FITTING PHASE\n",
    "df_array = census.to_numpy().reshape(n_states, -1, 6)\n",
    "res_states = {}\n",
    "\n",
    "def scale_data_by_pop(data):\n",
    "    # Step 1: Calculate the sum of the last three columns at time n=0\n",
    "    sum_last_three_cols = np.sum(data[:, 0, -3:], axis=1)\n",
    "    # Step 2: Reshape to make the division broadcastable\n",
    "    sum_last_three_cols = sum_last_three_cols[:, np.newaxis, np.newaxis]\n",
    "    # Step 3: Divide each trajectory by the sum\n",
    "    return data / sum_last_three_cols\n",
    "\n",
    "def scale_data_by_pop_single_state(data):\n",
    "    # Step 1: Calculate the sum of the last three columns at time n=0\n",
    "    sum_last_three_cols = np.sum(data[0, -3:])\n",
    "    # Step 2: Divide the entire trajectory by this sum\n",
    "    return data / sum_last_three_cols\n",
    "\n",
    "df_array = scale_data_by_pop(df_array)\n",
    "\n",
    "predictions_var = []\n",
    "\n",
    "\n",
    "def get_forecast(process, past_data, future_steps):\n",
    "    forecasts = []\n",
    "    for i in range(past_data.shape[0]):\n",
    "        forecast_trajectory = process.forecast(past_data[i], steps=future_steps)\n",
    "        forecasts.append(forecast_trajectory)\n",
    "    return np.array(forecasts)\n",
    "\n",
    "for state in range(n_states):\n",
    "    model = VAR(df_array[state, :, :])\n",
    "    lag_order = 1\n",
    "    res = estimate_bounded(model=model, lags=1, trend=\"c\")\n",
    "    tensor_lagged = to_lagged_tensor(df_array[state, :, :].reshape(1, -1, 6), lags=1)\n",
    "    tensor_lagged = tensor_lagged[0, :-1, :, :].transpose(1, 0, 2)\n",
    "    if forecast_horizon == 1:\n",
    "        prediction_state = get_forecast(res, tensor_lagged, forecast_horizon)[:, -1, :].reshape(-1, 6)\n",
    "        series_prediction_state = TimeSeries.from_times_and_values(series[0].time_index[1:], prediction_state, columns=cols)\n",
    "    else:\n",
    "        prediction_state = get_forecast(res, tensor_lagged, forecast_horizon)[input_chunk_length-1:-forecast_horizon+1, -1, :].reshape(-1, 6)\n",
    "        series_prediction_state = TimeSeries.from_times_and_values(time_index_series, prediction_state, columns=cols)\n",
    "    predictions_var.append(series_prediction_state)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6615a24d1cc614f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(predictions_var)):\n",
    "    predictions_var[i] = predictions_var[i].slice_intersect(test[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c738b0c9cebff3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "check_cols = ['Population 0-14', 'Population 15-64', 'Population 65+']\n",
    "print(f'Forecast Horizon: {forecast_horizon}')\n",
    "mae_var = []\n",
    "for i in range(len(test)):\n",
    "    for col in check_cols:\n",
    "        mae_var.append(mae(test[i][col], predictions_var[i][col]))\n",
    "print(f'var {np.mean(mae_var)}')\n",
    "\n",
    "\n",
    "mae_dlinear = []\n",
    "for i in range(len(test)):\n",
    "    for col in check_cols:\n",
    "        mae_dlinear.append(mae(test[i][col], predictions_dlinear[i][col]))\n",
    "print(f'dlinear {np.mean(mae_dlinear)}')\n",
    "\n",
    "mae_tsm = []\n",
    "for i in range(len(test)):\n",
    "    for col in check_cols:\n",
    "        mae_tsm.append(mae(test[i][col], predictions_tsm[i][col]))\n",
    "print(f'tsm {np.mean(mae_tsm)}')\n",
    "\n",
    "mae_tide = []\n",
    "for i in range(len(test)):\n",
    "    for col in check_cols:\n",
    "        mae_tide.append(mae(test[i][col], predictions_tide[i][col]))\n",
    "print(f'tide {np.mean(mae_tide)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6a92ef18acbffe9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_and_print_metrics():\n",
    "    check_cols = ['Population 0-14', 'Population 15-64', 'Population 65+']\n",
    "    metrics = [mae, smape, rmse]\n",
    "    metric_names = ['MAE', 'SMAPE', 'RMSE']\n",
    "\n",
    "    for metric, metric_name in zip(metrics, metric_names):\n",
    "        print(f'\\n{metric_name}:')\n",
    "        print(f'Forecast Horizon: {forecast_horizon}')\n",
    "\n",
    "        # Calculate metrics for each model\n",
    "        metric_var = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_var.append(metric(test[i][col], predictions_var[i][col]))\n",
    "        print(f'var {np.mean(metric_var)}')\n",
    "\n",
    "        metric_dlinear = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_dlinear.append(metric(test[i][col], predictions_dlinear[i][col]))\n",
    "        print(f'dlinear {np.mean(metric_dlinear)}')\n",
    "\n",
    "        metric_tsm = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_tsm.append(metric(test[i][col], predictions_tsm[i][col]))\n",
    "        print(f'tsm {np.mean(metric_tsm)}')\n",
    "\n",
    "        metric_tide = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_tide.append(metric(test[i][col], predictions_tide[i][col]))\n",
    "        print(f'tide {np.mean(metric_tide)}')\n",
    "\n",
    "        print()  # Add a blank line between metrics\n",
    "\n",
    "calculate_and_print_metrics()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26993a18cb57eb07"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from darts.metrics import smape, rmse, mae\n",
    "\n",
    "\n",
    "def calculate_and_print_metrics():\n",
    "    check_cols = ['Population 0-14', 'Population 15-64', 'Population 65+']\n",
    "    metrics = [mae, smape, rmse]\n",
    "    metric_names = ['MAE', 'SMAPE', 'RMSE']\n",
    "\n",
    "    for metric, metric_name in zip(metrics, metric_names):\n",
    "        print(f'\\n{metric_name}:')\n",
    "        print(f'Forecast Horizon: {forecast_horizon}')\n",
    "\n",
    "        # Calculate metrics for each model\n",
    "        metric_var = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_var.append(metric(test[i][col], predictions_var[i][col]))\n",
    "        print(f'var {np.mean(metric_var)}')\n",
    "\n",
    "        metric_dlinear = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_dlinear.append(metric(test[i][col], predictions_dlinear[i][col]))\n",
    "        print(f'dlinear {np.mean(metric_dlinear)}')\n",
    "\n",
    "        metric_tsm = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_tsm.append(metric(test[i][col], predictions_tsm[i][col]))\n",
    "        print(f'tsm {np.mean(metric_tsm)}')\n",
    "\n",
    "        metric_tide = []\n",
    "        for i in range(len(test)):\n",
    "            for col in check_cols:\n",
    "                metric_tide.append(metric(test[i][col], predictions_tide[i][col]))\n",
    "        print(f'tide {np.mean(metric_tide)}')\n",
    "\n",
    "        print()  # Add a blank line between metrics\n",
    "\n",
    "calculate_and_print_metrics()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e7cbbfc41269338"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "45e5b60d3f7a3a2b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
